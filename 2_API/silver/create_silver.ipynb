{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-18.1.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pyarrow-18.1.0-cp313-cp313-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/25.1 MB 8.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.7/25.1 MB 10.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 5.5/25.1 MB 10.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.1/25.1 MB 10.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 10.5/25.1 MB 10.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.3/25.1 MB 10.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.4/25.1 MB 10.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.8/25.1 MB 10.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.7/25.1 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.8/25.1 MB 10.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.1/25.1 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.1 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 10.0 MB/s eta 0:00:00\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-18.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silver_table.parquet not found. Creating Dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julia Muto\\AppData\\Local\\Temp\\ipykernel_5512\\4283618745.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_data = pd.concat([current_data, updated_data])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New rows added to the silver table!\n",
      "    ingestion_date_from ingestion_date_to symbol                      date  \\\n",
      "0            2024-11-20        2024-12-01   ABEV  2024-11-29T00:00:00.000Z   \n",
      "1            2024-11-20        2024-12-01   ABEV  2024-11-27T00:00:00.000Z   \n",
      "2            2024-11-20        2024-12-01   ABEV  2024-11-26T00:00:00.000Z   \n",
      "3            2024-11-20        2024-12-01   ABEV  2024-11-25T00:00:00.000Z   \n",
      "4            2024-11-20        2024-12-01   ABEV  2024-11-22T00:00:00.000Z   \n",
      "..                  ...               ...    ...                       ...   \n",
      "125          2024-11-30        2024-12-12   ERIC  2024-12-06T00:00:00.000Z   \n",
      "126          2024-11-30        2024-12-12   ERIC  2024-12-05T00:00:00.000Z   \n",
      "127          2024-11-30        2024-12-12   ERIC  2024-12-04T00:00:00.000Z   \n",
      "128          2024-11-30        2024-12-12   ERIC  2024-12-03T00:00:00.000Z   \n",
      "129          2024-11-30        2024-12-12   ERIC  2024-12-02T00:00:00.000Z   \n",
      "\n",
      "     open  high   low  close   volume  \n",
      "0    2.06  2.14  2.05   2.12  1530812  \n",
      "1    2.19  2.20  2.14   2.14  1661474  \n",
      "2    2.18  2.21  2.17   2.20   622062  \n",
      "3    2.20  2.21  2.17   2.17   394975  \n",
      "4    2.17  2.20  2.17   2.20   436940  \n",
      "..    ...   ...   ...    ...      ...  \n",
      "125  8.45  8.45  8.32   8.33   642727  \n",
      "126  8.38  8.47  8.38   8.46   851567  \n",
      "127  8.23  8.31  8.22   8.29   757417  \n",
      "128  8.28  8.28  8.18   8.19   527248  \n",
      "129  8.24  8.24  8.14   8.22   398026  \n",
      "\n",
      "[130 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "bronze_file = \"../bronze/bronze_data.json\"\n",
    "\n",
    "#read bronze table\n",
    "with open(bronze_file, \"r\") as file:\n",
    "    bronze_data = [json.loads(line) for line in file]\n",
    "\n",
    "silver_file = \"silver_table.parquet\"\n",
    "\n",
    "#convert json into dataframe and normalize data\n",
    "def convert_to_silver(bronze_data):\n",
    "    silver_data = []\n",
    "\n",
    "    for request in bronze_data:\n",
    "        #meta columns\n",
    "        ingestion_date_from = request[\"meta\"][\"date_from\"]\n",
    "        ingestion_date_to = request[\"meta\"][\"date_to\"]\n",
    "        symbol = request[\"symbol\"]\n",
    "        \n",
    "        #data for each date\n",
    "        for daily_data in request[\"data\"]:\n",
    "            silver_data.append({\n",
    "                \"ingestion_date_from\": ingestion_date_from,\n",
    "                \"ingestion_date_to\": ingestion_date_to,\n",
    "                \"symbol\": symbol,\n",
    "                \"date\": daily_data[\"date\"],\n",
    "                \"open\": daily_data[\"open\"],\n",
    "                \"high\": daily_data[\"high\"],\n",
    "                \"low\": daily_data[\"low\"],\n",
    "                \"close\": daily_data[\"close\"],\n",
    "                \"volume\": daily_data[\"volume\"]\n",
    "            })\n",
    "    \n",
    "    #save as dataframe\n",
    "    silver_df = pd.DataFrame(silver_data)\n",
    "\n",
    "    #convert types\n",
    "    silver_df[\"date\"] = pd.to_datetime(silver_df[\"date\"])\n",
    "    silver_df[\"ingestion_date_to\"] = pd.to_datetime(silver_df[\"ingestion_date_to\"])\n",
    "    silver_df[\"ingestion_date_from\"] = pd.to_datetime(silver_df[\"ingestion_date_from\"])\n",
    "    silver_df['symbol'] = silver_df['symbol'].astype('string')\n",
    "\n",
    "    return silver_df\n",
    "\n",
    "\n",
    "#add new rows to silver table\n",
    "def update_silver(updated_data, silver_file):\n",
    "    #check if file exists\n",
    "    if os.path.exists(silver_file):\n",
    "        print(f\"{silver_file} exists. Reading it...\")\n",
    "        current_data = pd.read_parquet(silver_file)\n",
    "    else:\n",
    "        print(f\"{silver_file} not found. Creating Dataframe\")\n",
    "        current_data = pd.DataFrame(columns=updated_data.columns)\n",
    "    \n",
    "    #add new rows and treat duplicates\n",
    "    all_data = pd.concat([current_data, updated_data])\n",
    "    all_data = all_data.drop_duplicates()\n",
    "    \n",
    "    #save table as parquet\n",
    "    all_data.to_parquet(silver_file)\n",
    "    \n",
    "    new_rows = all_data[~all_data.index.isin(current_data.index)]\n",
    "    if not new_rows.empty:\n",
    "        print(\"New rows added to the silver table!\")\n",
    "        print(new_rows)\n",
    "    else:\n",
    "        print(\"No new rows have been added to the silver table.\")\n",
    "\n",
    "\n",
    "#convert bronze json into silver format (not very efficient, as it loads everything from the bronze table every time)\n",
    "converted_bronze_data = convert_to_silver(bronze_data)\n",
    "\n",
    "#save new rows to silver table\n",
    "update_silver_table = update_silver(converted_bronze_data, silver_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ingestion_date_from ingestion_date_to symbol                      date  \\\n",
      "0            2024-11-20        2024-12-01   ABEV  2024-11-29T00:00:00.000Z   \n",
      "1            2024-11-20        2024-12-01   ABEV  2024-11-27T00:00:00.000Z   \n",
      "2            2024-11-20        2024-12-01   ABEV  2024-11-26T00:00:00.000Z   \n",
      "3            2024-11-20        2024-12-01   ABEV  2024-11-25T00:00:00.000Z   \n",
      "4            2024-11-20        2024-12-01   ABEV  2024-11-22T00:00:00.000Z   \n",
      "..                  ...               ...    ...                       ...   \n",
      "125          2024-11-30        2024-12-12   ERIC  2024-12-06T00:00:00.000Z   \n",
      "126          2024-11-30        2024-12-12   ERIC  2024-12-05T00:00:00.000Z   \n",
      "127          2024-11-30        2024-12-12   ERIC  2024-12-04T00:00:00.000Z   \n",
      "128          2024-11-30        2024-12-12   ERIC  2024-12-03T00:00:00.000Z   \n",
      "129          2024-11-30        2024-12-12   ERIC  2024-12-02T00:00:00.000Z   \n",
      "\n",
      "     open  high   low  close   volume  \n",
      "0    2.06  2.14  2.05   2.12  1530812  \n",
      "1    2.19  2.20  2.14   2.14  1661474  \n",
      "2    2.18  2.21  2.17   2.20   622062  \n",
      "3    2.20  2.21  2.17   2.17   394975  \n",
      "4    2.17  2.20  2.17   2.20   436940  \n",
      "..    ...   ...   ...    ...      ...  \n",
      "125  8.45  8.45  8.32   8.33   642727  \n",
      "126  8.38  8.47  8.38   8.46   851567  \n",
      "127  8.23  8.31  8.22   8.29   757417  \n",
      "128  8.28  8.28  8.18   8.19   527248  \n",
      "129  8.24  8.24  8.14   8.22   398026  \n",
      "\n",
      "[130 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "silver_df_check = pd.read_parquet(silver_file)\n",
    "\n",
    "print(silver_df_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingestion_date_from     object\n",
      "ingestion_date_to       object\n",
      "symbol                  object\n",
      "date                    object\n",
      "open                   float64\n",
      "high                   float64\n",
      "low                    float64\n",
      "close                  float64\n",
      "volume                   int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(silver_df_check.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
